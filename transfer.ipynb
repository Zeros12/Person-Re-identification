{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [data](#data)\n",
    "* [transfer](#transfer)\n",
    "* [eval](#eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.ion() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MarketDataset(Dataset):\n",
    "    def __init__(self, df, le=None, transform=None):\n",
    "        self.transform = transform\n",
    "        self.img_paths = np.array(df['pth'])\n",
    "        \n",
    "        if le is not None:\n",
    "            self.has_classes = True\n",
    "            self.classes = np.array(df['cl'].drop_duplicates())\n",
    "            self.labels = torch.from_numpy(le.transform((df['cl'])))\n",
    "        else:\n",
    "            self.has_classes = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.has_classes:\n",
    "            cl = self.labels[index]\n",
    "            return (img, cl)\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df(x):\n",
    "    df = pd.DataFrame({'pth': x})\n",
    "    df['cl'] = df.pth.apply(lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 12936\n"
     ]
    }
   ],
   "source": [
    "root = 'data/Market-1501-v15.09.15'\n",
    "paths = {\n",
    "    'train': 'bounding_box_train/*.jpg',\n",
    "    #'test': 'bounding_box_test/*.jpg',\n",
    "    #'query': 'query/*.jpg'\n",
    "}\n",
    "\n",
    "dfs = {\n",
    "    x: create_df(glob(os.path.join(root, paths[x])))for x in paths.keys()\n",
    "}\n",
    "\n",
    "for key in dfs.keys():\n",
    "    print(key, len(dfs[key]))\n",
    "    dfs[key].to_csv('%s.csv' % key, index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((751,), (693,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cl = np.array([int(x.split('/')[-1].split('_')[0]) for x in dfs['train']['pth']])\n",
    "train_tr, val_tr, train_tr_cl, val_tr_cl = train_test_split(dfs['train']['pth'], train_cl, test_size=0.1, random_state=18, stratify=train_cl)\n",
    "np.unique(train_tr_cl).shape, np.unique(val_tr_cl).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs['train_tr'] = create_df(train_tr)\n",
    "dfs['val_tr'] = create_df(val_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale([256, 256]),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Scale([256, 256]),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_dict = {\n",
    "    'train_tr': 'train',\n",
    "    'val_tr': 'test'\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: MarketDataset(dfs[x], le=le, transform=data_transforms[transform_dict[x]]) \n",
    "    for x in ['train_tr', 'val_tr']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloders = {\n",
    "    x[0]: torch.utils.data.DataLoader(image_datasets[x[0]], batch_size=x[1],\n",
    "                                      shuffle=True, num_workers=4)\n",
    "    for x in [('train_tr', 64), ('val_tr', 4)]\n",
    "}\n",
    "              \n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train_tr', 'val_tr']}\n",
    "class_names = image_datasets['train_tr'].classes\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train_tr', 'val_tr']:\n",
    "            if phase == 'train_tr':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for data in dataloders[phase]:\n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train_tr':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val_tr' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet (\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu): ReLU (inplace)\n",
       "  (maxpool): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
       "  (layer1): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (3): Bottleneck (\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (3): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (4): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (5): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential (\n",
       "    (0): Bottleneck (\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "      (downsample): Sequential (\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck (\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "    (2): Bottleneck (\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU (inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d (size=7, stride=7, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (fc): Sequential (\n",
       "    (dropout): Dropout (p = 0.75)\n",
       "    (fc1): Linear (2048 -> 751)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv = models.resnet50(pretrained=True)\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = torch.nn.Sequential()\n",
    "model_conv.fc.add_module('dropout', torch.nn.Dropout(p=0.75))\n",
    "model_conv.fc.add_module('fc1', nn.Linear(num_ftrs, 751))\n",
    "\n",
    "if use_gpu:\n",
    "    model_conv = model_conv.cuda()\n",
    "    \n",
    "model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_conv.fc.parameters(), lr=0.1, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train_tr Loss: 0.1549 Acc: 0.0176\n",
      "val_tr Loss: 0.1372 Acc: 0.0603\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train_tr Loss: 0.1858 Acc: 0.0459\n",
      "val_tr Loss: 0.1311 Acc: 0.1028\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train_tr Loss: 0.2028 Acc: 0.0581\n",
      "val_tr Loss: 0.1399 Acc: 0.1128\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train_tr Loss: 0.2221 Acc: 0.0708\n",
      "val_tr Loss: 0.1389 Acc: 0.1461\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train_tr Loss: 0.2255 Acc: 0.0858\n",
      "val_tr Loss: 0.1384 Acc: 0.1816\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train_tr Loss: 0.2355 Acc: 0.0929\n",
      "val_tr Loss: 0.1454 Acc: 0.1685\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train_tr Loss: 0.2461 Acc: 0.0949\n",
      "val_tr Loss: 0.1449 Acc: 0.1971\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train_tr Loss: 0.2062 Acc: 0.1312\n",
      "val_tr Loss: 0.0834 Acc: 0.3138\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train_tr Loss: 0.1879 Acc: 0.1449\n",
      "val_tr Loss: 0.0790 Acc: 0.3207\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train_tr Loss: 0.1873 Acc: 0.1438\n",
      "val_tr Loss: 0.0779 Acc: 0.3369\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train_tr Loss: 0.1829 Acc: 0.1457\n",
      "val_tr Loss: 0.0757 Acc: 0.3400\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train_tr Loss: 0.1790 Acc: 0.1484\n",
      "val_tr Loss: 0.0750 Acc: 0.3308\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train_tr Loss: 0.1757 Acc: 0.1528\n",
      "val_tr Loss: 0.0759 Acc: 0.3485\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train_tr Loss: 0.1729 Acc: 0.1585\n",
      "val_tr Loss: 0.0727 Acc: 0.3617\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train_tr Loss: 0.1667 Acc: 0.1659\n",
      "val_tr Loss: 0.0691 Acc: 0.3648\n",
      "\n",
      "Training complete in 15m 49s\n",
      "Best test Acc: 0.364760\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_ft,\n",
    "                         exp_lr_scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#torch.save(model_conv, 'finetuned_resnet_market_fc_lr1s7g1.pt')\n",
    "model_conv = torch.load('finetuned_resnet_market_fc_lr1s7g1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.0.conv3.weight\n",
      "layer1.0.bn3.weight\n",
      "layer1.0.bn3.bias\n",
      "layer1.0.downsample.0.weight\n",
      "layer1.0.downsample.1.weight\n",
      "layer1.0.downsample.1.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.1.conv3.weight\n",
      "layer1.1.bn3.weight\n",
      "layer1.1.bn3.bias\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer1.2.conv3.weight\n",
      "layer1.2.bn3.weight\n",
      "layer1.2.bn3.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.conv3.weight\n",
      "layer2.0.bn3.weight\n",
      "layer2.0.bn3.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.1.conv3.weight\n",
      "layer2.1.bn3.weight\n",
      "layer2.1.bn3.bias\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.2.conv3.weight\n",
      "layer2.2.bn3.weight\n",
      "layer2.2.bn3.bias\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer2.3.conv3.weight\n",
      "layer2.3.bn3.weight\n",
      "layer2.3.bn3.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.conv3.weight\n",
      "layer3.0.bn3.weight\n",
      "layer3.0.bn3.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.1.conv3.weight\n",
      "layer3.1.bn3.weight\n",
      "layer3.1.bn3.bias\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.2.conv3.weight\n",
      "layer3.2.bn3.weight\n",
      "layer3.2.bn3.bias\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.3.conv3.weight\n",
      "layer3.3.bn3.weight\n",
      "layer3.3.bn3.bias\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.4.conv3.weight\n",
      "layer3.4.bn3.weight\n",
      "layer3.4.bn3.bias\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer3.5.conv3.weight\n",
      "layer3.5.bn3.weight\n",
      "layer3.5.bn3.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.conv3.weight\n",
      "layer4.0.bn3.weight\n",
      "layer4.0.bn3.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.conv3.weight\n",
      "layer4.1.bn3.weight\n",
      "layer4.1.bn3.bias\n",
      "layer4.2.conv1.weight\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.conv2.weight\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "layer4.2.conv3.weight\n",
      "layer4.2.bn3.weight\n",
      "layer4.2.bn3.bias\n",
      "fc.fc1.weight\n",
      "fc.fc1.bias\n"
     ]
    }
   ],
   "source": [
    "params_dict = dict(model_conv.named_parameters())\n",
    "params = []\n",
    "for key, value in params_dict.items():\n",
    "    print(key)\n",
    "    if ('conv1' in key) & (not 'layer' in key):\n",
    "        params += [{'params':[value],'lr':0.00001}]\n",
    "    elif ('conv' in key):# | ('fc1' in key):\n",
    "        params += [{'params':[value],'lr':0.002}]\n",
    "    elif ('fc1' in key):\n",
    "        params += [{'params':[value],'lr':0.1}]\n",
    "    elif 'bias' in key:\n",
    "        params += [{'params':[value], 'lr':0.0001, 'weight_decay':0}]\n",
    "    else:\n",
    "        params += [{'params':[value], 'lr':0.0001}] #'weight_decay':0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(params, momentum=0.9, weight_decay=0.0001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=40, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# without fc finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train_tr Loss: 0.1031 Acc: 0.0489\n",
      "val_tr Loss: 1.0796 Acc: 0.2179\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train_tr Loss: 0.0623 Acc: 0.2287\n",
      "val_tr Loss: 0.6090 Acc: 0.4745\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train_tr Loss: 0.0419 Acc: 0.4157\n",
      "val_tr Loss: 0.3895 Acc: 0.6321\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train_tr Loss: 0.0305 Acc: 0.5404\n",
      "val_tr Loss: 0.2844 Acc: 0.7272\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train_tr Loss: 0.0224 Acc: 0.6422\n",
      "val_tr Loss: 0.2246 Acc: 0.7728\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train_tr Loss: 0.0169 Acc: 0.7183\n",
      "val_tr Loss: 0.1659 Acc: 0.8400\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train_tr Loss: 0.0135 Acc: 0.7681\n",
      "val_tr Loss: 0.1558 Acc: 0.8408\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train_tr Loss: 0.0110 Acc: 0.8085\n",
      "val_tr Loss: 0.1312 Acc: 0.8787\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train_tr Loss: 0.0089 Acc: 0.8399\n",
      "val_tr Loss: 0.1188 Acc: 0.8825\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train_tr Loss: 0.0075 Acc: 0.8657\n",
      "val_tr Loss: 0.1063 Acc: 0.8957\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train_tr Loss: 0.0061 Acc: 0.8852\n",
      "val_tr Loss: 0.1017 Acc: 0.9019\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train_tr Loss: 0.0051 Acc: 0.9056\n",
      "val_tr Loss: 0.0999 Acc: 0.9019\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train_tr Loss: 0.0044 Acc: 0.9196\n",
      "val_tr Loss: 0.0878 Acc: 0.9150\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train_tr Loss: 0.0037 Acc: 0.9268\n",
      "val_tr Loss: 0.0906 Acc: 0.9134\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train_tr Loss: 0.0032 Acc: 0.9400\n",
      "val_tr Loss: 0.0811 Acc: 0.9274\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train_tr Loss: 0.0027 Acc: 0.9499\n",
      "val_tr Loss: 0.0782 Acc: 0.9274\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train_tr Loss: 0.0024 Acc: 0.9548\n",
      "val_tr Loss: 0.0875 Acc: 0.9165\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train_tr Loss: 0.0022 Acc: 0.9582\n",
      "val_tr Loss: 0.0804 Acc: 0.9304\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train_tr Loss: 0.0020 Acc: 0.9633\n",
      "val_tr Loss: 0.0753 Acc: 0.9266\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train_tr Loss: 0.0017 Acc: 0.9688\n",
      "val_tr Loss: 0.0679 Acc: 0.9335\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train_tr Loss: 0.0015 Acc: 0.9745\n",
      "val_tr Loss: 0.0735 Acc: 0.9335\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train_tr Loss: 0.0015 Acc: 0.9727\n",
      "val_tr Loss: 0.0709 Acc: 0.9351\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train_tr Loss: 0.0013 Acc: 0.9763\n",
      "val_tr Loss: 0.0683 Acc: 0.9428\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train_tr Loss: 0.0011 Acc: 0.9784\n",
      "val_tr Loss: 0.0629 Acc: 0.9420\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train_tr Loss: 0.0011 Acc: 0.9794\n",
      "val_tr Loss: 0.0702 Acc: 0.9405\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train_tr Loss: 0.0010 Acc: 0.9804\n",
      "val_tr Loss: 0.0675 Acc: 0.9420\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train_tr Loss: 0.0008 Acc: 0.9853\n",
      "val_tr Loss: 0.0677 Acc: 0.9397\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train_tr Loss: 0.0008 Acc: 0.9860\n",
      "val_tr Loss: 0.0645 Acc: 0.9459\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train_tr Loss: 0.0007 Acc: 0.9879\n",
      "val_tr Loss: 0.0641 Acc: 0.9498\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train_tr Loss: 0.0006 Acc: 0.9888\n",
      "val_tr Loss: 0.0711 Acc: 0.9444\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train_tr Loss: 0.0007 Acc: 0.9887\n",
      "val_tr Loss: 0.0639 Acc: 0.9490\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train_tr Loss: 0.0006 Acc: 0.9896\n",
      "val_tr Loss: 0.0677 Acc: 0.9420\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train_tr Loss: 0.0005 Acc: 0.9908\n",
      "val_tr Loss: 0.0658 Acc: 0.9474\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train_tr Loss: 0.0005 Acc: 0.9930\n",
      "val_tr Loss: 0.0610 Acc: 0.9498\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train_tr Loss: 0.0006 Acc: 0.9911\n",
      "val_tr Loss: 0.0664 Acc: 0.9436\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train_tr Loss: 0.0006 Acc: 0.9912\n",
      "val_tr Loss: 0.0622 Acc: 0.9521\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train_tr Loss: 0.0004 Acc: 0.9928\n",
      "val_tr Loss: 0.0552 Acc: 0.9513\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train_tr Loss: 0.0003 Acc: 0.9951\n",
      "val_tr Loss: 0.0656 Acc: 0.9490\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train_tr Loss: 0.0004 Acc: 0.9942\n",
      "val_tr Loss: 0.0613 Acc: 0.9482\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train_tr Loss: 0.0004 Acc: 0.9931\n",
      "val_tr Loss: 0.0741 Acc: 0.9420\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train_tr Loss: 0.0004 Acc: 0.9945\n",
      "val_tr Loss: 0.0623 Acc: 0.9490\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9976\n",
      "val_tr Loss: 0.0592 Acc: 0.9521\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9967\n",
      "val_tr Loss: 0.0616 Acc: 0.9560\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9978\n",
      "val_tr Loss: 0.0569 Acc: 0.9567\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9975\n",
      "val_tr Loss: 0.0557 Acc: 0.9560\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9972\n",
      "val_tr Loss: 0.0552 Acc: 0.9575\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9978\n",
      "val_tr Loss: 0.0549 Acc: 0.9575\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9980\n",
      "val_tr Loss: 0.0518 Acc: 0.9583\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9982\n",
      "val_tr Loss: 0.0527 Acc: 0.9575\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train_tr Loss: 0.0002 Acc: 0.9984\n",
      "val_tr Loss: 0.0521 Acc: 0.9552\n",
      "\n",
      "Training complete in 156m 6s\n",
      "Best test Acc: 0.958269\n"
     ]
    }
   ],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_ft,\n",
    "                         exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_conv, 'finetuned_resnet_market_all.pt')\n",
    "#model = torch.load('finetuned_resnet_market_all.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#torch.save(model_conv, 'finetuned_resnet_market_fc_lr1s7g1_market_all.pt')\n",
    "#model = torch.load('finetuned_resnet_market_fc_lr1s7g1_market_all.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MarketDataset(Dataset):\n",
    "    def __init__(self, df, le=None, check_junk_distractor=False, transform=None):\n",
    "        self.transform = transform\n",
    "        self.img_paths = np.array(df['pth'])\n",
    "        \n",
    "        if le is not None:\n",
    "            self.has_classes = True\n",
    "            self.classes = np.array(df['cl'].drop_duplicates())\n",
    "            self.labels = torch.from_numpy(le.transform((df['cl'])))\n",
    "        else:\n",
    "            self.has_classes = False\n",
    "            \n",
    "        if check_junk_distractor:\n",
    "            self.junk = df[df['cl'] == '-1']['pth']\n",
    "            self.distractor = df[df['cl'] == '0000']['pth']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.has_classes:\n",
    "            cl = self.labels[index]\n",
    "            return (img, cl)\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df(x):\n",
    "    df = pd.DataFrame({'pth': x})\n",
    "    df['cl'] = df.pth.apply(lambda x: int(x.split('/')[-1].split('_')[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = 'data/Market-1501-v15.09.15'\n",
    "paths = {\n",
    "    #'train': 'bounding_box_train/*.jpg',\n",
    "    'test': 'bounding_box_test/*.jpg',\n",
    "    'query': 'query/*.jpg'\n",
    "}\n",
    "\n",
    "dfs = {\n",
    "    x: create_df(glob(os.path.join(root, paths[x])))for x in paths.keys()\n",
    "}\n",
    "\n",
    "for key in dfs.keys():\n",
    "    print(key, len(dfs[key]))\n",
    "    dfs[key].to_csv('%s.csv' % key, index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_dict = {\n",
    "    'test': 'test',\n",
    "    'query': 'test'\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x[0]: MarketDataset(dfs[x], le=x[1], check_junk_distractor=x[2] transform=data_transforms[transform_dict[x]]) \n",
    "    for x in [('test', le, True), ('query', None, True)]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
